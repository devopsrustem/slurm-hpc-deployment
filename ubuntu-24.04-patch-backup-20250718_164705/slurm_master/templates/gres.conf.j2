# =============================================================================
# SLURM GRES CONFIGURATION FILE - GENERATED BY ANSIBLE
# =============================================================================
#
# gres.conf - Generic Resource (GRES) Configuration File for Slurm
# Generated automatically by Ansible - DO NOT EDIT MANUALLY
#
# This file defines the generic resources available on each node
# Documentation: https://slurm.schedmd.com/gres.conf.html
# =============================================================================

{% if slurm_enable_gres | default(true) %}
# =============================================================================
# GLOBAL GRES CONFIGURATION
# =============================================================================

# AutoDetect configuration
# Automatically detect GPU resources using nvidia-ml-py
{% if slurm_gres_autodetect | default(true) %}
AutoDetect=nvml
{% endif %}

# =============================================================================
# NODE-SPECIFIC GPU CONFIGURATION
# =============================================================================

{% for node_group in slurm_node_groups %}
{% if node_group.gres is defined and 'gpu' in node_group.gres %}
# {{ node_group.name | upper }} - GPU CONFIGURATION
{% set gpu_info = node_group.gpu_config | default({}) %}
{% if gpu_info.type is defined %}
# GPU Type: {{ gpu_info.type }}
# GPU Count: {{ gpu_info.count | default(8) }}
# GPU Memory: {{ gpu_info.memory | default('80gb') }}

{% if gpu_info.manual_config | default(false) %}
# Manual GPU configuration for {{ node_group.nodes }}
{% for i in range(gpu_info.count | default(8)) %}
NodeName={{ node_group.nodes }} Name=gpu Type={{ gpu_info.type }} File=/dev/nvidia{{ i }}{% if gpu_info.cores is defined %} Cores={{ gpu_info.cores }}{% endif %}{% if gpu_info.links is defined %} Links={{ gpu_info.links }}{% endif %}

{% endfor %}
{% else %}
# Automatic GPU detection for {{ node_group.nodes }}
# GPUs will be detected automatically using NVML
{% endif %}

{% else %}
# Default GPU configuration for {{ node_group.nodes }}
# Using automatic detection
{% endif %}

{% endif %}
{% endfor %}

# =============================================================================
# DGX H100 SPECIFIC CONFIGURATION
# =============================================================================
{% if slurm_dgx_h100_config | default(false) %}
# DGX H100 nodes - 8x H100 80GB GPUs with NVLink
# NodeName pattern: cn[01-64]
# Each H100 has 80GB HBM3 memory and NVLink 4.0 connectivity

{% for dgx_node_group in slurm_dgx_node_groups | default([]) %}
# DGX H100 Node Group: {{ dgx_node_group.name }}
{% for i in range(8) %}
NodeName={{ dgx_node_group.nodes }} Name=gpu Type=h100 File=/dev/nvidia{{ i }} Cores=0-13{% if i < 4 %},14-27{% else %},28-41,42-55{% endif %} Links={{ i }},{{ (i + 1) % 8 }}{% if i < 4 %},{{ i + 4 }}{% else %},{{ i - 4 }}{% endif %}

{% endfor %}
{% endfor %}
{% endif %}

# =============================================================================
# MIG (MULTI-INSTANCE GPU) CONFIGURATION
# =============================================================================
{% if slurm_enable_mig | default(false) %}
# MIG configuration for A100/H100 GPUs
# Allows GPU partitioning for better resource utilization

{% for mig_config in slurm_mig_configurations | default([]) %}
# MIG Configuration: {{ mig_config.name }}
# GPU{{ mig_config.gpu_id }}: {{ mig_config.instances | length }} instances
{% for instance in mig_config.instances %}
NodeName={{ mig_config.nodes }} Name=gpu Type={{ instance.type }} File=/dev/nvidia{{ mig_config.gpu_id }} MultipleFiles=/dev/nvidia-caps/nvidia-cap{{ instance.cap_id }}{% if instance.cores is defined %} Cores={{ instance.cores }}{% endif %}

{% endfor %}
{% endfor %}
{% endif %}

# =============================================================================
# CUSTOM GPU CONFIGURATIONS
# =============================================================================
{% if slurm_custom_gpu_configs is defined %}
{% for custom_config in slurm_custom_gpu_configs %}
# Custom GPU Configuration: {{ custom_config.name }}
{% for gpu_def in custom_config.definitions %}
NodeName={{ gpu_def.nodes }} Name={{ gpu_def.name }} Type={{ gpu_def.type }}{% if gpu_def.file is defined %} File={{ gpu_def.file }}{% endif %}{% if gpu_def.cores is defined %} Cores={{ gpu_def.cores }}{% endif %}{% if gpu_def.links is defined %} Links={{ gpu_def.links }}{% endif %}{% if gpu_def.multiple_files is defined %} MultipleFiles={{ gpu_def.multiple_files }}{% endif %}

{% endfor %}
{% endfor %}
{% endif %}

# =============================================================================
# OTHER GRES RESOURCES  
# =============================================================================

{% if slurm_enable_network_gres | default(false) %}
# High-speed network interfaces (InfiniBand, etc.)
{% for node_group in slurm_node_groups %}
{% if node_group.network_gres is defined %}
# Network GRES for {{ node_group.name }}
{% for net_gres in node_group.network_gres %}
NodeName={{ node_group.nodes }} Name={{ net_gres.name }} Type={{ net_gres.type }}{% if net_gres.file is defined %} File={{ net_gres.file }}{% endif %}{% if net_gres.count is defined %} Count={{ net_gres.count }}{% endif %}

{% endfor %}
{% endif %}
{% endfor %}
{% endif %}

{% if slurm_enable_storage_gres | default(false) %}
# Local storage resources (NVMe, etc.)
{% for node_group in slurm_node_groups %}
{% if node_group.storage_gres is defined %}
# Storage GRES for {{ node_group.name }}
{% for storage_gres in node_group.storage_gres %}
NodeName={{ node_group.nodes }} Name={{ storage_gres.name }} Type={{ storage_gres.type }}{% if storage_gres.file is defined %} File={{ storage_gres.file }}{% endif %}{% if storage_gres.count is defined %} Count={{ storage_gres.count }}{% endif %}

{% endfor %}
{% endif %}
{% endfor %}
{% endif %}

{% if slurm_enable_fpga_gres | default(false) %}
# FPGA resources
{% for node_group in slurm_node_groups %}
{% if node_group.fpga_gres is defined %}
# FPGA GRES for {{ node_group.name }}
{% for fpga_gres in node_group.fpga_gres %}
NodeName={{ node_group.nodes }} Name={{ fpga_gres.name }} Type={{ fpga_gres.type }}{% if fpga_gres.file is defined %} File={{ fpga_gres.file }}{% endif %}{% if fpga_gres.count is defined %} Count={{ fpga_gres.count }}{% endif %}

{% endfor %}
{% endif %}
{% endfor %}
{% endif %}

# =============================================================================
# VALIDATION AND DEBUGGING
# =============================================================================
{% if slurm_gres_debug | default(false) %}
# Debug information for GRES configuration
# Use 'scontrol show node' to verify GRES detection
# Use 'sinfo -o "%20N %10c %10m %25f %10G"' to see GRES availability
# Use 'squeue -o "%18i %9P %20j %8u %8T %10M %9l %6D %20S %20f %20b"' to see GRES allocation
{% endif %}

{% else %}
# =============================================================================
# GRES DISABLED
# =============================================================================
# GRES support is disabled in the configuration
# To enable GRES, set slurm_enable_gres: true in your Ansible variables
{% endif %}

# =============================================================================
# END OF GRES CONFIGURATION
# =============================================================================